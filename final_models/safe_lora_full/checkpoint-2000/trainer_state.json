{
  "best_global_step": 2000,
  "best_metric": 2.0038576126098633,
  "best_model_checkpoint": "/content/NLP-Final-Project/final_models/safe_lora_full/checkpoint-2000",
  "epoch": 1.0282776349614395,
  "eval_steps": 1000,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02570694087403599,
      "grad_norm": 0.2888001799583435,
      "learning_rate": 2.94e-05,
      "loss": 3.068,
      "step": 50
    },
    {
      "epoch": 0.05141388174807198,
      "grad_norm": 0.2675626575946808,
      "learning_rate": 5.94e-05,
      "loss": 2.9765,
      "step": 100
    },
    {
      "epoch": 0.07712082262210797,
      "grad_norm": 0.27300798892974854,
      "learning_rate": 8.939999999999999e-05,
      "loss": 2.7954,
      "step": 150
    },
    {
      "epoch": 0.10282776349614396,
      "grad_norm": 0.29250088334083557,
      "learning_rate": 0.0001194,
      "loss": 2.6492,
      "step": 200
    },
    {
      "epoch": 0.12853470437017994,
      "grad_norm": 0.2880370020866394,
      "learning_rate": 0.0001494,
      "loss": 2.5585,
      "step": 250
    },
    {
      "epoch": 0.15424164524421594,
      "grad_norm": 0.3389185965061188,
      "learning_rate": 0.00017939999999999997,
      "loss": 2.508,
      "step": 300
    },
    {
      "epoch": 0.17994858611825193,
      "grad_norm": 0.2845611870288849,
      "learning_rate": 0.00020939999999999997,
      "loss": 2.4805,
      "step": 350
    },
    {
      "epoch": 0.20565552699228792,
      "grad_norm": 0.42546528577804565,
      "learning_rate": 0.0002394,
      "loss": 2.4379,
      "step": 400
    },
    {
      "epoch": 0.23136246786632392,
      "grad_norm": 0.324501097202301,
      "learning_rate": 0.0002694,
      "loss": 2.4098,
      "step": 450
    },
    {
      "epoch": 0.2570694087403599,
      "grad_norm": 0.2973443269729614,
      "learning_rate": 0.00029939999999999996,
      "loss": 2.4207,
      "step": 500
    },
    {
      "epoch": 0.2827763496143959,
      "grad_norm": 0.3259581923484802,
      "learning_rate": 0.000297244611059044,
      "loss": 2.3981,
      "step": 550
    },
    {
      "epoch": 0.30848329048843187,
      "grad_norm": 0.3640042841434479,
      "learning_rate": 0.0002944329896907216,
      "loss": 2.3717,
      "step": 600
    },
    {
      "epoch": 0.3341902313624679,
      "grad_norm": 0.30008459091186523,
      "learning_rate": 0.0002916213683223992,
      "loss": 2.3367,
      "step": 650
    },
    {
      "epoch": 0.35989717223650386,
      "grad_norm": 0.30775395035743713,
      "learning_rate": 0.00028880974695407683,
      "loss": 2.3468,
      "step": 700
    },
    {
      "epoch": 0.3856041131105398,
      "grad_norm": 0.3447073698043823,
      "learning_rate": 0.00028599812558575445,
      "loss": 2.3298,
      "step": 750
    },
    {
      "epoch": 0.41131105398457585,
      "grad_norm": 0.3351374864578247,
      "learning_rate": 0.000283186504217432,
      "loss": 2.332,
      "step": 800
    },
    {
      "epoch": 0.4370179948586118,
      "grad_norm": 0.3539056181907654,
      "learning_rate": 0.00028037488284910964,
      "loss": 2.3264,
      "step": 850
    },
    {
      "epoch": 0.46272493573264784,
      "grad_norm": 0.3343728482723236,
      "learning_rate": 0.0002775632614807872,
      "loss": 2.3305,
      "step": 900
    },
    {
      "epoch": 0.4884318766066838,
      "grad_norm": 0.34385424852371216,
      "learning_rate": 0.0002747516401124648,
      "loss": 2.3083,
      "step": 950
    },
    {
      "epoch": 0.5141388174807198,
      "grad_norm": 0.33327165246009827,
      "learning_rate": 0.00027194001874414244,
      "loss": 2.3202,
      "step": 1000
    },
    {
      "epoch": 0.5141388174807198,
      "eval_loss": 2.052823781967163,
      "eval_runtime": 233.7228,
      "eval_samples_per_second": 29.591,
      "eval_steps_per_second": 3.701,
      "step": 1000
    },
    {
      "epoch": 0.5398457583547558,
      "grad_norm": 0.3219482898712158,
      "learning_rate": 0.00026912839737582006,
      "loss": 2.3049,
      "step": 1050
    },
    {
      "epoch": 0.5655526992287918,
      "grad_norm": 0.32164934277534485,
      "learning_rate": 0.00026631677600749763,
      "loss": 2.296,
      "step": 1100
    },
    {
      "epoch": 0.5912596401028277,
      "grad_norm": 0.39899536967277527,
      "learning_rate": 0.00026350515463917525,
      "loss": 2.312,
      "step": 1150
    },
    {
      "epoch": 0.6169665809768637,
      "grad_norm": 0.3342379927635193,
      "learning_rate": 0.0002606935332708528,
      "loss": 2.2847,
      "step": 1200
    },
    {
      "epoch": 0.6426735218508998,
      "grad_norm": 0.3419879972934723,
      "learning_rate": 0.00025788191190253044,
      "loss": 2.2777,
      "step": 1250
    },
    {
      "epoch": 0.6683804627249358,
      "grad_norm": 0.3610823154449463,
      "learning_rate": 0.000255070290534208,
      "loss": 2.2876,
      "step": 1300
    },
    {
      "epoch": 0.6940874035989717,
      "grad_norm": 0.34512561559677124,
      "learning_rate": 0.0002522586691658856,
      "loss": 2.2877,
      "step": 1350
    },
    {
      "epoch": 0.7197943444730077,
      "grad_norm": 0.3550092577934265,
      "learning_rate": 0.00024944704779756324,
      "loss": 2.281,
      "step": 1400
    },
    {
      "epoch": 0.7455012853470437,
      "grad_norm": 0.36090853810310364,
      "learning_rate": 0.00024663542642924086,
      "loss": 2.2761,
      "step": 1450
    },
    {
      "epoch": 0.7712082262210797,
      "grad_norm": 0.40657418966293335,
      "learning_rate": 0.00024382380506091846,
      "loss": 2.2782,
      "step": 1500
    },
    {
      "epoch": 0.7969151670951157,
      "grad_norm": 0.3868419826030731,
      "learning_rate": 0.00024101218369259602,
      "loss": 2.2866,
      "step": 1550
    },
    {
      "epoch": 0.8226221079691517,
      "grad_norm": 0.4128686189651489,
      "learning_rate": 0.00023820056232427364,
      "loss": 2.2613,
      "step": 1600
    },
    {
      "epoch": 0.8483290488431876,
      "grad_norm": 0.35133516788482666,
      "learning_rate": 0.00023538894095595123,
      "loss": 2.2701,
      "step": 1650
    },
    {
      "epoch": 0.8740359897172236,
      "grad_norm": 0.3069288730621338,
      "learning_rate": 0.00023257731958762886,
      "loss": 2.2584,
      "step": 1700
    },
    {
      "epoch": 0.8997429305912596,
      "grad_norm": 0.39268580079078674,
      "learning_rate": 0.00022976569821930645,
      "loss": 2.2614,
      "step": 1750
    },
    {
      "epoch": 0.9254498714652957,
      "grad_norm": 0.3316993713378906,
      "learning_rate": 0.00022695407685098404,
      "loss": 2.2565,
      "step": 1800
    },
    {
      "epoch": 0.9511568123393316,
      "grad_norm": 0.367911159992218,
      "learning_rate": 0.00022414245548266163,
      "loss": 2.2666,
      "step": 1850
    },
    {
      "epoch": 0.9768637532133676,
      "grad_norm": 0.32786738872528076,
      "learning_rate": 0.00022133083411433925,
      "loss": 2.237,
      "step": 1900
    },
    {
      "epoch": 1.0025706940874035,
      "grad_norm": 0.38917386531829834,
      "learning_rate": 0.00021851921274601685,
      "loss": 2.2619,
      "step": 1950
    },
    {
      "epoch": 1.0282776349614395,
      "grad_norm": 0.379116028547287,
      "learning_rate": 0.00021570759137769447,
      "loss": 2.2528,
      "step": 2000
    },
    {
      "epoch": 1.0282776349614395,
      "eval_loss": 2.0038576126098633,
      "eval_runtime": 233.7298,
      "eval_samples_per_second": 29.59,
      "eval_steps_per_second": 3.701,
      "step": 2000
    }
  ],
  "logging_steps": 50,
  "max_steps": 5835,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1989023030184960.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
