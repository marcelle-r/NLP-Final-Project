{
  "best_global_step": 5000,
  "best_metric": 1.9612445831298828,
  "best_model_checkpoint": "/content/NLP-Final-Project/final_models/safe_lora_full/checkpoint-5000",
  "epoch": 2.570694087403599,
  "eval_steps": 1000,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02570694087403599,
      "grad_norm": 0.2888001799583435,
      "learning_rate": 2.94e-05,
      "loss": 3.068,
      "step": 50
    },
    {
      "epoch": 0.05141388174807198,
      "grad_norm": 0.2675626575946808,
      "learning_rate": 5.94e-05,
      "loss": 2.9765,
      "step": 100
    },
    {
      "epoch": 0.07712082262210797,
      "grad_norm": 0.27300798892974854,
      "learning_rate": 8.939999999999999e-05,
      "loss": 2.7954,
      "step": 150
    },
    {
      "epoch": 0.10282776349614396,
      "grad_norm": 0.29250088334083557,
      "learning_rate": 0.0001194,
      "loss": 2.6492,
      "step": 200
    },
    {
      "epoch": 0.12853470437017994,
      "grad_norm": 0.2880370020866394,
      "learning_rate": 0.0001494,
      "loss": 2.5585,
      "step": 250
    },
    {
      "epoch": 0.15424164524421594,
      "grad_norm": 0.3389185965061188,
      "learning_rate": 0.00017939999999999997,
      "loss": 2.508,
      "step": 300
    },
    {
      "epoch": 0.17994858611825193,
      "grad_norm": 0.2845611870288849,
      "learning_rate": 0.00020939999999999997,
      "loss": 2.4805,
      "step": 350
    },
    {
      "epoch": 0.20565552699228792,
      "grad_norm": 0.42546528577804565,
      "learning_rate": 0.0002394,
      "loss": 2.4379,
      "step": 400
    },
    {
      "epoch": 0.23136246786632392,
      "grad_norm": 0.324501097202301,
      "learning_rate": 0.0002694,
      "loss": 2.4098,
      "step": 450
    },
    {
      "epoch": 0.2570694087403599,
      "grad_norm": 0.2973443269729614,
      "learning_rate": 0.00029939999999999996,
      "loss": 2.4207,
      "step": 500
    },
    {
      "epoch": 0.2827763496143959,
      "grad_norm": 0.3259581923484802,
      "learning_rate": 0.000297244611059044,
      "loss": 2.3981,
      "step": 550
    },
    {
      "epoch": 0.30848329048843187,
      "grad_norm": 0.3640042841434479,
      "learning_rate": 0.0002944329896907216,
      "loss": 2.3717,
      "step": 600
    },
    {
      "epoch": 0.3341902313624679,
      "grad_norm": 0.30008459091186523,
      "learning_rate": 0.0002916213683223992,
      "loss": 2.3367,
      "step": 650
    },
    {
      "epoch": 0.35989717223650386,
      "grad_norm": 0.30775395035743713,
      "learning_rate": 0.00028880974695407683,
      "loss": 2.3468,
      "step": 700
    },
    {
      "epoch": 0.3856041131105398,
      "grad_norm": 0.3447073698043823,
      "learning_rate": 0.00028599812558575445,
      "loss": 2.3298,
      "step": 750
    },
    {
      "epoch": 0.41131105398457585,
      "grad_norm": 0.3351374864578247,
      "learning_rate": 0.000283186504217432,
      "loss": 2.332,
      "step": 800
    },
    {
      "epoch": 0.4370179948586118,
      "grad_norm": 0.3539056181907654,
      "learning_rate": 0.00028037488284910964,
      "loss": 2.3264,
      "step": 850
    },
    {
      "epoch": 0.46272493573264784,
      "grad_norm": 0.3343728482723236,
      "learning_rate": 0.0002775632614807872,
      "loss": 2.3305,
      "step": 900
    },
    {
      "epoch": 0.4884318766066838,
      "grad_norm": 0.34385424852371216,
      "learning_rate": 0.0002747516401124648,
      "loss": 2.3083,
      "step": 950
    },
    {
      "epoch": 0.5141388174807198,
      "grad_norm": 0.33327165246009827,
      "learning_rate": 0.00027194001874414244,
      "loss": 2.3202,
      "step": 1000
    },
    {
      "epoch": 0.5141388174807198,
      "eval_loss": 2.052823781967163,
      "eval_runtime": 233.7228,
      "eval_samples_per_second": 29.591,
      "eval_steps_per_second": 3.701,
      "step": 1000
    },
    {
      "epoch": 0.5398457583547558,
      "grad_norm": 0.3219482898712158,
      "learning_rate": 0.00026912839737582006,
      "loss": 2.3049,
      "step": 1050
    },
    {
      "epoch": 0.5655526992287918,
      "grad_norm": 0.32164934277534485,
      "learning_rate": 0.00026631677600749763,
      "loss": 2.296,
      "step": 1100
    },
    {
      "epoch": 0.5912596401028277,
      "grad_norm": 0.39899536967277527,
      "learning_rate": 0.00026350515463917525,
      "loss": 2.312,
      "step": 1150
    },
    {
      "epoch": 0.6169665809768637,
      "grad_norm": 0.3342379927635193,
      "learning_rate": 0.0002606935332708528,
      "loss": 2.2847,
      "step": 1200
    },
    {
      "epoch": 0.6426735218508998,
      "grad_norm": 0.3419879972934723,
      "learning_rate": 0.00025788191190253044,
      "loss": 2.2777,
      "step": 1250
    },
    {
      "epoch": 0.6683804627249358,
      "grad_norm": 0.3610823154449463,
      "learning_rate": 0.000255070290534208,
      "loss": 2.2876,
      "step": 1300
    },
    {
      "epoch": 0.6940874035989717,
      "grad_norm": 0.34512561559677124,
      "learning_rate": 0.0002522586691658856,
      "loss": 2.2877,
      "step": 1350
    },
    {
      "epoch": 0.7197943444730077,
      "grad_norm": 0.3550092577934265,
      "learning_rate": 0.00024944704779756324,
      "loss": 2.281,
      "step": 1400
    },
    {
      "epoch": 0.7455012853470437,
      "grad_norm": 0.36090853810310364,
      "learning_rate": 0.00024663542642924086,
      "loss": 2.2761,
      "step": 1450
    },
    {
      "epoch": 0.7712082262210797,
      "grad_norm": 0.40657418966293335,
      "learning_rate": 0.00024382380506091846,
      "loss": 2.2782,
      "step": 1500
    },
    {
      "epoch": 0.7969151670951157,
      "grad_norm": 0.3868419826030731,
      "learning_rate": 0.00024101218369259602,
      "loss": 2.2866,
      "step": 1550
    },
    {
      "epoch": 0.8226221079691517,
      "grad_norm": 0.4128686189651489,
      "learning_rate": 0.00023820056232427364,
      "loss": 2.2613,
      "step": 1600
    },
    {
      "epoch": 0.8483290488431876,
      "grad_norm": 0.35133516788482666,
      "learning_rate": 0.00023538894095595123,
      "loss": 2.2701,
      "step": 1650
    },
    {
      "epoch": 0.8740359897172236,
      "grad_norm": 0.3069288730621338,
      "learning_rate": 0.00023257731958762886,
      "loss": 2.2584,
      "step": 1700
    },
    {
      "epoch": 0.8997429305912596,
      "grad_norm": 0.39268580079078674,
      "learning_rate": 0.00022976569821930645,
      "loss": 2.2614,
      "step": 1750
    },
    {
      "epoch": 0.9254498714652957,
      "grad_norm": 0.3316993713378906,
      "learning_rate": 0.00022695407685098404,
      "loss": 2.2565,
      "step": 1800
    },
    {
      "epoch": 0.9511568123393316,
      "grad_norm": 0.367911159992218,
      "learning_rate": 0.00022414245548266163,
      "loss": 2.2666,
      "step": 1850
    },
    {
      "epoch": 0.9768637532133676,
      "grad_norm": 0.32786738872528076,
      "learning_rate": 0.00022133083411433925,
      "loss": 2.237,
      "step": 1900
    },
    {
      "epoch": 1.0025706940874035,
      "grad_norm": 0.38917386531829834,
      "learning_rate": 0.00021851921274601685,
      "loss": 2.2619,
      "step": 1950
    },
    {
      "epoch": 1.0282776349614395,
      "grad_norm": 0.379116028547287,
      "learning_rate": 0.00021570759137769447,
      "loss": 2.2528,
      "step": 2000
    },
    {
      "epoch": 1.0282776349614395,
      "eval_loss": 2.0038576126098633,
      "eval_runtime": 233.7298,
      "eval_samples_per_second": 29.59,
      "eval_steps_per_second": 3.701,
      "step": 2000
    },
    {
      "epoch": 1.0539845758354756,
      "grad_norm": 0.3393447697162628,
      "learning_rate": 0.00021289597000937203,
      "loss": 2.2556,
      "step": 2050
    },
    {
      "epoch": 1.0796915167095116,
      "grad_norm": 0.3375919759273529,
      "learning_rate": 0.00021008434864104965,
      "loss": 2.2445,
      "step": 2100
    },
    {
      "epoch": 1.1053984575835476,
      "grad_norm": 0.3401522934436798,
      "learning_rate": 0.00020727272727272725,
      "loss": 2.2364,
      "step": 2150
    },
    {
      "epoch": 1.1311053984575836,
      "grad_norm": 0.3448432683944702,
      "learning_rate": 0.00020446110590440487,
      "loss": 2.2309,
      "step": 2200
    },
    {
      "epoch": 1.1568123393316196,
      "grad_norm": 0.36094921827316284,
      "learning_rate": 0.00020164948453608246,
      "loss": 2.2356,
      "step": 2250
    },
    {
      "epoch": 1.1825192802056554,
      "grad_norm": 0.3557991683483124,
      "learning_rate": 0.00019883786316776005,
      "loss": 2.2248,
      "step": 2300
    },
    {
      "epoch": 1.2082262210796915,
      "grad_norm": 0.3745674192905426,
      "learning_rate": 0.00019602624179943765,
      "loss": 2.2347,
      "step": 2350
    },
    {
      "epoch": 1.2339331619537275,
      "grad_norm": 0.34560611844062805,
      "learning_rate": 0.00019321462043111527,
      "loss": 2.2276,
      "step": 2400
    },
    {
      "epoch": 1.2596401028277635,
      "grad_norm": 0.35534384846687317,
      "learning_rate": 0.00019040299906279286,
      "loss": 2.2423,
      "step": 2450
    },
    {
      "epoch": 1.2853470437017995,
      "grad_norm": 0.3741677701473236,
      "learning_rate": 0.00018759137769447045,
      "loss": 2.2374,
      "step": 2500
    },
    {
      "epoch": 1.3110539845758356,
      "grad_norm": 0.37123793363571167,
      "learning_rate": 0.00018477975632614805,
      "loss": 2.2415,
      "step": 2550
    },
    {
      "epoch": 1.3367609254498714,
      "grad_norm": 0.3874707520008087,
      "learning_rate": 0.00018196813495782567,
      "loss": 2.243,
      "step": 2600
    },
    {
      "epoch": 1.3624678663239074,
      "grad_norm": 0.3860761225223541,
      "learning_rate": 0.00017915651358950326,
      "loss": 2.2664,
      "step": 2650
    },
    {
      "epoch": 1.3881748071979434,
      "grad_norm": 0.3426264226436615,
      "learning_rate": 0.00017634489222118088,
      "loss": 2.231,
      "step": 2700
    },
    {
      "epoch": 1.4138817480719794,
      "grad_norm": 0.35051336884498596,
      "learning_rate": 0.00017353327085285845,
      "loss": 2.2286,
      "step": 2750
    },
    {
      "epoch": 1.4395886889460154,
      "grad_norm": 0.34449654817581177,
      "learning_rate": 0.00017072164948453607,
      "loss": 2.2348,
      "step": 2800
    },
    {
      "epoch": 1.4652956298200515,
      "grad_norm": 0.34504497051239014,
      "learning_rate": 0.00016791002811621366,
      "loss": 2.2186,
      "step": 2850
    },
    {
      "epoch": 1.4910025706940875,
      "grad_norm": 0.34326910972595215,
      "learning_rate": 0.00016509840674789128,
      "loss": 2.2372,
      "step": 2900
    },
    {
      "epoch": 1.5167095115681235,
      "grad_norm": 0.3549782335758209,
      "learning_rate": 0.00016228678537956887,
      "loss": 2.2284,
      "step": 2950
    },
    {
      "epoch": 1.5424164524421595,
      "grad_norm": 0.35893121361732483,
      "learning_rate": 0.00015947516401124647,
      "loss": 2.2083,
      "step": 3000
    },
    {
      "epoch": 1.5424164524421595,
      "eval_loss": 1.9844655990600586,
      "eval_runtime": 234.0324,
      "eval_samples_per_second": 29.551,
      "eval_steps_per_second": 3.696,
      "step": 3000
    },
    {
      "epoch": 1.5681233933161953,
      "grad_norm": 0.38431793451309204,
      "learning_rate": 0.00015666354264292406,
      "loss": 2.2149,
      "step": 3050
    },
    {
      "epoch": 1.5938303341902313,
      "grad_norm": 0.3700384199619293,
      "learning_rate": 0.00015385192127460168,
      "loss": 2.2014,
      "step": 3100
    },
    {
      "epoch": 1.6195372750642674,
      "grad_norm": 0.36442601680755615,
      "learning_rate": 0.00015104029990627927,
      "loss": 2.2287,
      "step": 3150
    },
    {
      "epoch": 1.6452442159383034,
      "grad_norm": 0.3341714143753052,
      "learning_rate": 0.00014822867853795686,
      "loss": 2.2195,
      "step": 3200
    },
    {
      "epoch": 1.6709511568123392,
      "grad_norm": 0.35594552755355835,
      "learning_rate": 0.00014541705716963449,
      "loss": 2.251,
      "step": 3250
    },
    {
      "epoch": 1.6966580976863752,
      "grad_norm": 0.3914144039154053,
      "learning_rate": 0.00014260543580131208,
      "loss": 2.2247,
      "step": 3300
    },
    {
      "epoch": 1.7223650385604112,
      "grad_norm": 0.37513670325279236,
      "learning_rate": 0.00013979381443298967,
      "loss": 2.2071,
      "step": 3350
    },
    {
      "epoch": 1.7480719794344473,
      "grad_norm": 0.32945239543914795,
      "learning_rate": 0.00013698219306466726,
      "loss": 2.1991,
      "step": 3400
    },
    {
      "epoch": 1.7737789203084833,
      "grad_norm": 0.3803463578224182,
      "learning_rate": 0.00013417057169634488,
      "loss": 2.2207,
      "step": 3450
    },
    {
      "epoch": 1.7994858611825193,
      "grad_norm": 0.38973966240882874,
      "learning_rate": 0.00013135895032802248,
      "loss": 2.1942,
      "step": 3500
    },
    {
      "epoch": 1.8251928020565553,
      "grad_norm": 0.4011722207069397,
      "learning_rate": 0.00012854732895970007,
      "loss": 2.2078,
      "step": 3550
    },
    {
      "epoch": 1.8508997429305913,
      "grad_norm": 0.3643723726272583,
      "learning_rate": 0.0001257357075913777,
      "loss": 2.2047,
      "step": 3600
    },
    {
      "epoch": 1.8766066838046274,
      "grad_norm": 0.38385072350502014,
      "learning_rate": 0.00012292408622305528,
      "loss": 2.2075,
      "step": 3650
    },
    {
      "epoch": 1.9023136246786634,
      "grad_norm": 0.34746772050857544,
      "learning_rate": 0.00012011246485473289,
      "loss": 2.2084,
      "step": 3700
    },
    {
      "epoch": 1.9280205655526992,
      "grad_norm": 0.37054386734962463,
      "learning_rate": 0.00011730084348641048,
      "loss": 2.2175,
      "step": 3750
    },
    {
      "epoch": 1.9537275064267352,
      "grad_norm": 0.36615079641342163,
      "learning_rate": 0.00011448922211808809,
      "loss": 2.2244,
      "step": 3800
    },
    {
      "epoch": 1.9794344473007712,
      "grad_norm": 0.3299681842327118,
      "learning_rate": 0.0001116776007497657,
      "loss": 2.2149,
      "step": 3850
    },
    {
      "epoch": 2.005141388174807,
      "grad_norm": 0.35234448313713074,
      "learning_rate": 0.00010886597938144329,
      "loss": 2.1822,
      "step": 3900
    },
    {
      "epoch": 2.030848329048843,
      "grad_norm": 0.3973124325275421,
      "learning_rate": 0.0001060543580131209,
      "loss": 2.2172,
      "step": 3950
    },
    {
      "epoch": 2.056555269922879,
      "grad_norm": 0.40429091453552246,
      "learning_rate": 0.00010324273664479849,
      "loss": 2.2002,
      "step": 4000
    },
    {
      "epoch": 2.056555269922879,
      "eval_loss": 1.9689826965332031,
      "eval_runtime": 233.6784,
      "eval_samples_per_second": 29.596,
      "eval_steps_per_second": 3.702,
      "step": 4000
    },
    {
      "epoch": 2.082262210796915,
      "grad_norm": 0.35408350825309753,
      "learning_rate": 0.0001004311152764761,
      "loss": 2.2036,
      "step": 4050
    },
    {
      "epoch": 2.107969151670951,
      "grad_norm": 0.3534035086631775,
      "learning_rate": 9.76194939081537e-05,
      "loss": 2.2043,
      "step": 4100
    },
    {
      "epoch": 2.133676092544987,
      "grad_norm": 0.37244758009910583,
      "learning_rate": 9.48078725398313e-05,
      "loss": 2.2134,
      "step": 4150
    },
    {
      "epoch": 2.159383033419023,
      "grad_norm": 0.3848394453525543,
      "learning_rate": 9.19962511715089e-05,
      "loss": 2.2079,
      "step": 4200
    },
    {
      "epoch": 2.185089974293059,
      "grad_norm": 0.3638564348220825,
      "learning_rate": 8.91846298031865e-05,
      "loss": 2.2164,
      "step": 4250
    },
    {
      "epoch": 2.210796915167095,
      "grad_norm": 0.34015288949012756,
      "learning_rate": 8.63730084348641e-05,
      "loss": 2.1795,
      "step": 4300
    },
    {
      "epoch": 2.236503856041131,
      "grad_norm": 0.3955039978027344,
      "learning_rate": 8.35613870665417e-05,
      "loss": 2.1915,
      "step": 4350
    },
    {
      "epoch": 2.2622107969151672,
      "grad_norm": 0.3705078661441803,
      "learning_rate": 8.07497656982193e-05,
      "loss": 2.2125,
      "step": 4400
    },
    {
      "epoch": 2.2879177377892033,
      "grad_norm": 0.37740471959114075,
      "learning_rate": 7.793814432989691e-05,
      "loss": 2.2051,
      "step": 4450
    },
    {
      "epoch": 2.3136246786632393,
      "grad_norm": 0.3724636435508728,
      "learning_rate": 7.51265229615745e-05,
      "loss": 2.1981,
      "step": 4500
    },
    {
      "epoch": 2.3393316195372753,
      "grad_norm": 0.3697358965873718,
      "learning_rate": 7.231490159325211e-05,
      "loss": 2.1905,
      "step": 4550
    },
    {
      "epoch": 2.365038560411311,
      "grad_norm": 0.3569897711277008,
      "learning_rate": 6.95032802249297e-05,
      "loss": 2.2027,
      "step": 4600
    },
    {
      "epoch": 2.390745501285347,
      "grad_norm": 0.35225751996040344,
      "learning_rate": 6.669165885660731e-05,
      "loss": 2.1943,
      "step": 4650
    },
    {
      "epoch": 2.416452442159383,
      "grad_norm": 0.37181615829467773,
      "learning_rate": 6.38800374882849e-05,
      "loss": 2.2019,
      "step": 4700
    },
    {
      "epoch": 2.442159383033419,
      "grad_norm": 0.3694556653499603,
      "learning_rate": 6.106841611996251e-05,
      "loss": 2.1951,
      "step": 4750
    },
    {
      "epoch": 2.467866323907455,
      "grad_norm": 0.36634954810142517,
      "learning_rate": 5.82567947516401e-05,
      "loss": 2.2039,
      "step": 4800
    },
    {
      "epoch": 2.493573264781491,
      "grad_norm": 0.34405702352523804,
      "learning_rate": 5.5445173383317715e-05,
      "loss": 2.1909,
      "step": 4850
    },
    {
      "epoch": 2.519280205655527,
      "grad_norm": 0.36008578538894653,
      "learning_rate": 5.2633552014995315e-05,
      "loss": 2.1958,
      "step": 4900
    },
    {
      "epoch": 2.544987146529563,
      "grad_norm": 0.3605206608772278,
      "learning_rate": 4.9821930646672915e-05,
      "loss": 2.1927,
      "step": 4950
    },
    {
      "epoch": 2.570694087403599,
      "grad_norm": 0.37187543511390686,
      "learning_rate": 4.701030927835051e-05,
      "loss": 2.1977,
      "step": 5000
    },
    {
      "epoch": 2.570694087403599,
      "eval_loss": 1.9612445831298828,
      "eval_runtime": 233.985,
      "eval_samples_per_second": 29.557,
      "eval_steps_per_second": 3.697,
      "step": 5000
    }
  ],
  "logging_steps": 50,
  "max_steps": 5835,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4976072158464000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
