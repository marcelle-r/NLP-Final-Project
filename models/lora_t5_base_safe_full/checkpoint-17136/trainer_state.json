{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 17136,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02334267040149393,
      "grad_norm": 0.7580406665802002,
      "learning_rate": 0.000199,
      "loss": 2.2728,
      "step": 200
    },
    {
      "epoch": 0.04668534080298786,
      "grad_norm": 0.7558180689811707,
      "learning_rate": 0.00039900000000000005,
      "loss": 1.7988,
      "step": 400
    },
    {
      "epoch": 0.0700280112044818,
      "grad_norm": 0.7829858064651489,
      "learning_rate": 0.0004970245251262322,
      "loss": 1.6889,
      "step": 600
    },
    {
      "epoch": 0.09337068160597572,
      "grad_norm": 0.8874818682670593,
      "learning_rate": 0.0004910134647751864,
      "loss": 1.6527,
      "step": 800
    },
    {
      "epoch": 0.11671335200746966,
      "grad_norm": 0.876214325428009,
      "learning_rate": 0.00048500240442414045,
      "loss": 1.6209,
      "step": 1000
    },
    {
      "epoch": 0.1400560224089636,
      "grad_norm": 0.8010538220405579,
      "learning_rate": 0.0004789913440730945,
      "loss": 1.5924,
      "step": 1200
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.7506723403930664,
      "learning_rate": 0.0004729802837220486,
      "loss": 1.5944,
      "step": 1400
    },
    {
      "epoch": 0.18674136321195145,
      "grad_norm": 0.817037045955658,
      "learning_rate": 0.00046696922337100265,
      "loss": 1.5709,
      "step": 1600
    },
    {
      "epoch": 0.21008403361344538,
      "grad_norm": 0.5677698254585266,
      "learning_rate": 0.0004609581630199567,
      "loss": 1.5586,
      "step": 1800
    },
    {
      "epoch": 0.2334267040149393,
      "grad_norm": 0.9165205955505371,
      "learning_rate": 0.00045494710266891084,
      "loss": 1.5403,
      "step": 2000
    },
    {
      "epoch": 0.2567693744164332,
      "grad_norm": 0.8720977306365967,
      "learning_rate": 0.0004489360423178649,
      "loss": 1.5444,
      "step": 2200
    },
    {
      "epoch": 0.2801120448179272,
      "grad_norm": 0.8513222336769104,
      "learning_rate": 0.000442924981966819,
      "loss": 1.5311,
      "step": 2400
    },
    {
      "epoch": 0.3034547152194211,
      "grad_norm": 0.7448260188102722,
      "learning_rate": 0.00043691392161577305,
      "loss": 1.4938,
      "step": 2600
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.6955282092094421,
      "learning_rate": 0.0004309028612647271,
      "loss": 1.5295,
      "step": 2800
    },
    {
      "epoch": 0.35014005602240894,
      "grad_norm": 0.7074407339096069,
      "learning_rate": 0.0004248918009136812,
      "loss": 1.4966,
      "step": 3000
    },
    {
      "epoch": 0.3734827264239029,
      "grad_norm": 0.9372289776802063,
      "learning_rate": 0.00041888074056263525,
      "loss": 1.5013,
      "step": 3200
    },
    {
      "epoch": 0.3968253968253968,
      "grad_norm": 0.647857666015625,
      "learning_rate": 0.0004128696802115893,
      "loss": 1.4939,
      "step": 3400
    },
    {
      "epoch": 0.42016806722689076,
      "grad_norm": 0.7450749278068542,
      "learning_rate": 0.0004068586198605434,
      "loss": 1.4959,
      "step": 3600
    },
    {
      "epoch": 0.44351073762838467,
      "grad_norm": 0.7816101312637329,
      "learning_rate": 0.00040084755950949746,
      "loss": 1.4824,
      "step": 3800
    },
    {
      "epoch": 0.4668534080298786,
      "grad_norm": 0.8706156015396118,
      "learning_rate": 0.0003948364991584515,
      "loss": 1.4978,
      "step": 4000
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.5861271023750305,
      "learning_rate": 0.0003888254388074056,
      "loss": 1.484,
      "step": 4200
    },
    {
      "epoch": 0.5135387488328664,
      "grad_norm": 0.6216872930526733,
      "learning_rate": 0.0003828143784563597,
      "loss": 1.4777,
      "step": 4400
    },
    {
      "epoch": 0.5368814192343604,
      "grad_norm": 0.7683542370796204,
      "learning_rate": 0.0003768033181053138,
      "loss": 1.4734,
      "step": 4600
    },
    {
      "epoch": 0.5602240896358543,
      "grad_norm": 0.7216247916221619,
      "learning_rate": 0.00037079225775426785,
      "loss": 1.4732,
      "step": 4800
    },
    {
      "epoch": 0.5835667600373483,
      "grad_norm": 0.9333914518356323,
      "learning_rate": 0.0003647811974032219,
      "loss": 1.4686,
      "step": 5000
    },
    {
      "epoch": 0.6069094304388422,
      "grad_norm": 0.6958417296409607,
      "learning_rate": 0.00035877013705217604,
      "loss": 1.4502,
      "step": 5200
    },
    {
      "epoch": 0.6302521008403361,
      "grad_norm": 0.6581032872200012,
      "learning_rate": 0.0003527590767011301,
      "loss": 1.4475,
      "step": 5400
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.6337523460388184,
      "learning_rate": 0.0003467480163500842,
      "loss": 1.4575,
      "step": 5600
    },
    {
      "epoch": 0.676937441643324,
      "grad_norm": 0.7830178141593933,
      "learning_rate": 0.00034073695599903825,
      "loss": 1.4513,
      "step": 5800
    },
    {
      "epoch": 0.7002801120448179,
      "grad_norm": 0.8764787316322327,
      "learning_rate": 0.0003347258956479923,
      "loss": 1.4445,
      "step": 6000
    },
    {
      "epoch": 0.7236227824463118,
      "grad_norm": 0.7800812721252441,
      "learning_rate": 0.0003287148352969464,
      "loss": 1.4397,
      "step": 6200
    },
    {
      "epoch": 0.7469654528478058,
      "grad_norm": 0.7462452054023743,
      "learning_rate": 0.00032270377494590045,
      "loss": 1.4536,
      "step": 6400
    },
    {
      "epoch": 0.7703081232492998,
      "grad_norm": 0.8572536706924438,
      "learning_rate": 0.00031669271459485457,
      "loss": 1.4294,
      "step": 6600
    },
    {
      "epoch": 0.7936507936507936,
      "grad_norm": 0.7442865371704102,
      "learning_rate": 0.00031068165424380864,
      "loss": 1.4199,
      "step": 6800
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.652764081954956,
      "learning_rate": 0.0003046705938927627,
      "loss": 1.4516,
      "step": 7000
    },
    {
      "epoch": 0.8403361344537815,
      "grad_norm": 0.8390893340110779,
      "learning_rate": 0.0002986595335417168,
      "loss": 1.4375,
      "step": 7200
    },
    {
      "epoch": 0.8636788048552755,
      "grad_norm": 0.8314042687416077,
      "learning_rate": 0.00029264847319067084,
      "loss": 1.4329,
      "step": 7400
    },
    {
      "epoch": 0.8870214752567693,
      "grad_norm": 0.6945003271102905,
      "learning_rate": 0.0002866374128396249,
      "loss": 1.4572,
      "step": 7600
    },
    {
      "epoch": 0.9103641456582633,
      "grad_norm": 0.7823024392127991,
      "learning_rate": 0.000280626352488579,
      "loss": 1.4212,
      "step": 7800
    },
    {
      "epoch": 0.9337068160597572,
      "grad_norm": 0.691249668598175,
      "learning_rate": 0.00027461529213753305,
      "loss": 1.4348,
      "step": 8000
    },
    {
      "epoch": 0.9570494864612512,
      "grad_norm": 0.7723042964935303,
      "learning_rate": 0.0002686042317864871,
      "loss": 1.4186,
      "step": 8200
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.8396820425987244,
      "learning_rate": 0.0002625931714354412,
      "loss": 1.447,
      "step": 8400
    },
    {
      "epoch": 1.003734827264239,
      "grad_norm": 0.8284738063812256,
      "learning_rate": 0.00025658211108439525,
      "loss": 1.4142,
      "step": 8600
    },
    {
      "epoch": 1.0270774976657329,
      "grad_norm": 0.7672239542007446,
      "learning_rate": 0.0002505710507333493,
      "loss": 1.4122,
      "step": 8800
    },
    {
      "epoch": 1.050420168067227,
      "grad_norm": 0.6916917562484741,
      "learning_rate": 0.00024455999038230344,
      "loss": 1.4011,
      "step": 9000
    },
    {
      "epoch": 1.0737628384687208,
      "grad_norm": 0.7875794172286987,
      "learning_rate": 0.0002385489300312575,
      "loss": 1.4238,
      "step": 9200
    },
    {
      "epoch": 1.0971055088702149,
      "grad_norm": 0.7121228575706482,
      "learning_rate": 0.0002325378696802116,
      "loss": 1.4028,
      "step": 9400
    },
    {
      "epoch": 1.1204481792717087,
      "grad_norm": 0.7265099883079529,
      "learning_rate": 0.00022652680932916568,
      "loss": 1.4178,
      "step": 9600
    },
    {
      "epoch": 1.1437908496732025,
      "grad_norm": 0.8488279581069946,
      "learning_rate": 0.00022051574897811974,
      "loss": 1.4213,
      "step": 9800
    },
    {
      "epoch": 1.1671335200746966,
      "grad_norm": 0.8127245306968689,
      "learning_rate": 0.0002145046886270738,
      "loss": 1.3934,
      "step": 10000
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 0.7357327342033386,
      "learning_rate": 0.00020849362827602788,
      "loss": 1.3935,
      "step": 10200
    },
    {
      "epoch": 1.2138188608776843,
      "grad_norm": 0.8371660113334656,
      "learning_rate": 0.00020248256792498195,
      "loss": 1.4247,
      "step": 10400
    },
    {
      "epoch": 1.2371615312791784,
      "grad_norm": 0.7652649879455566,
      "learning_rate": 0.00019647150757393607,
      "loss": 1.4013,
      "step": 10600
    },
    {
      "epoch": 1.2605042016806722,
      "grad_norm": 0.7282648682594299,
      "learning_rate": 0.00019046044722289014,
      "loss": 1.4162,
      "step": 10800
    },
    {
      "epoch": 1.283846872082166,
      "grad_norm": 0.7290958762168884,
      "learning_rate": 0.0001844493868718442,
      "loss": 1.4018,
      "step": 11000
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 0.7158153057098389,
      "learning_rate": 0.00017843832652079828,
      "loss": 1.4069,
      "step": 11200
    },
    {
      "epoch": 1.330532212885154,
      "grad_norm": 1.0535025596618652,
      "learning_rate": 0.00017242726616975234,
      "loss": 1.3989,
      "step": 11400
    },
    {
      "epoch": 1.353874883286648,
      "grad_norm": 0.823574960231781,
      "learning_rate": 0.0001664162058187064,
      "loss": 1.4001,
      "step": 11600
    },
    {
      "epoch": 1.377217553688142,
      "grad_norm": 0.7955030798912048,
      "learning_rate": 0.0001604051454676605,
      "loss": 1.4135,
      "step": 11800
    },
    {
      "epoch": 1.4005602240896358,
      "grad_norm": 0.9474555850028992,
      "learning_rate": 0.00015439408511661458,
      "loss": 1.3908,
      "step": 12000
    },
    {
      "epoch": 1.4239028944911298,
      "grad_norm": 0.8405323624610901,
      "learning_rate": 0.00014838302476556864,
      "loss": 1.3795,
      "step": 12200
    },
    {
      "epoch": 1.4472455648926237,
      "grad_norm": 0.7641283273696899,
      "learning_rate": 0.0001423719644145227,
      "loss": 1.3734,
      "step": 12400
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 0.7721649408340454,
      "learning_rate": 0.00013636090406347678,
      "loss": 1.3982,
      "step": 12600
    },
    {
      "epoch": 1.4939309056956116,
      "grad_norm": 0.7001602053642273,
      "learning_rate": 0.00013034984371243087,
      "loss": 1.4206,
      "step": 12800
    },
    {
      "epoch": 1.5172735760971054,
      "grad_norm": 0.8603981733322144,
      "learning_rate": 0.00012433878336138494,
      "loss": 1.4017,
      "step": 13000
    },
    {
      "epoch": 1.5406162464985993,
      "grad_norm": 0.7498703002929688,
      "learning_rate": 0.00011832772301033902,
      "loss": 1.3957,
      "step": 13200
    },
    {
      "epoch": 1.5639589169000934,
      "grad_norm": 0.7945023775100708,
      "learning_rate": 0.0001123166626592931,
      "loss": 1.3798,
      "step": 13400
    },
    {
      "epoch": 1.5873015873015874,
      "grad_norm": 0.7433431148529053,
      "learning_rate": 0.00010630560230824717,
      "loss": 1.3806,
      "step": 13600
    },
    {
      "epoch": 1.6106442577030813,
      "grad_norm": 0.7479729056358337,
      "learning_rate": 0.00010029454195720126,
      "loss": 1.4047,
      "step": 13800
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 1.0000544786453247,
      "learning_rate": 9.428348160615532e-05,
      "loss": 1.3827,
      "step": 14000
    },
    {
      "epoch": 1.657329598506069,
      "grad_norm": 0.9384610056877136,
      "learning_rate": 8.827242125510939e-05,
      "loss": 1.3964,
      "step": 14200
    },
    {
      "epoch": 1.680672268907563,
      "grad_norm": 0.9256441593170166,
      "learning_rate": 8.226136090406349e-05,
      "loss": 1.3848,
      "step": 14400
    },
    {
      "epoch": 1.7040149393090571,
      "grad_norm": 0.8324000835418701,
      "learning_rate": 7.625030055301756e-05,
      "loss": 1.3831,
      "step": 14600
    },
    {
      "epoch": 1.727357609710551,
      "grad_norm": 0.7810972332954407,
      "learning_rate": 7.023924020197162e-05,
      "loss": 1.3597,
      "step": 14800
    },
    {
      "epoch": 1.7507002801120448,
      "grad_norm": 0.8368092775344849,
      "learning_rate": 6.42281798509257e-05,
      "loss": 1.3792,
      "step": 15000
    },
    {
      "epoch": 1.7740429505135387,
      "grad_norm": 0.7526261210441589,
      "learning_rate": 5.821711949987978e-05,
      "loss": 1.3969,
      "step": 15200
    },
    {
      "epoch": 1.7973856209150327,
      "grad_norm": 0.7340947389602661,
      "learning_rate": 5.2206059148833856e-05,
      "loss": 1.3931,
      "step": 15400
    },
    {
      "epoch": 1.8207282913165266,
      "grad_norm": 0.6985543370246887,
      "learning_rate": 4.619499879778793e-05,
      "loss": 1.3948,
      "step": 15600
    },
    {
      "epoch": 1.8440709617180207,
      "grad_norm": 0.7862669229507446,
      "learning_rate": 4.0183938446742006e-05,
      "loss": 1.3913,
      "step": 15800
    },
    {
      "epoch": 1.8674136321195145,
      "grad_norm": 0.7318160533905029,
      "learning_rate": 3.417287809569608e-05,
      "loss": 1.3928,
      "step": 16000
    },
    {
      "epoch": 1.8907563025210083,
      "grad_norm": 0.7534971237182617,
      "learning_rate": 2.8161817744650156e-05,
      "loss": 1.3828,
      "step": 16200
    },
    {
      "epoch": 1.9140989729225022,
      "grad_norm": 0.8004279732704163,
      "learning_rate": 2.2150757393604234e-05,
      "loss": 1.3847,
      "step": 16400
    },
    {
      "epoch": 1.9374416433239963,
      "grad_norm": 0.9563373923301697,
      "learning_rate": 1.6139697042558306e-05,
      "loss": 1.3965,
      "step": 16600
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 0.7247211337089539,
      "learning_rate": 1.0128636691512382e-05,
      "loss": 1.3776,
      "step": 16800
    },
    {
      "epoch": 1.9841269841269842,
      "grad_norm": 0.7916432023048401,
      "learning_rate": 4.117576340466459e-06,
      "loss": 1.3679,
      "step": 17000
    }
  ],
  "logging_steps": 200,
  "max_steps": 17136,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2082459243110400.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
