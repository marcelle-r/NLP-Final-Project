{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 8568,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02334267040149393,
      "grad_norm": 0.7580406665802002,
      "learning_rate": 0.000199,
      "loss": 2.2728,
      "step": 200
    },
    {
      "epoch": 0.04668534080298786,
      "grad_norm": 0.7558180689811707,
      "learning_rate": 0.00039900000000000005,
      "loss": 1.7988,
      "step": 400
    },
    {
      "epoch": 0.0700280112044818,
      "grad_norm": 0.7829858064651489,
      "learning_rate": 0.0004970245251262322,
      "loss": 1.6889,
      "step": 600
    },
    {
      "epoch": 0.09337068160597572,
      "grad_norm": 0.8874818682670593,
      "learning_rate": 0.0004910134647751864,
      "loss": 1.6527,
      "step": 800
    },
    {
      "epoch": 0.11671335200746966,
      "grad_norm": 0.876214325428009,
      "learning_rate": 0.00048500240442414045,
      "loss": 1.6209,
      "step": 1000
    },
    {
      "epoch": 0.1400560224089636,
      "grad_norm": 0.8010538220405579,
      "learning_rate": 0.0004789913440730945,
      "loss": 1.5924,
      "step": 1200
    },
    {
      "epoch": 0.16339869281045752,
      "grad_norm": 0.7506723403930664,
      "learning_rate": 0.0004729802837220486,
      "loss": 1.5944,
      "step": 1400
    },
    {
      "epoch": 0.18674136321195145,
      "grad_norm": 0.817037045955658,
      "learning_rate": 0.00046696922337100265,
      "loss": 1.5709,
      "step": 1600
    },
    {
      "epoch": 0.21008403361344538,
      "grad_norm": 0.5677698254585266,
      "learning_rate": 0.0004609581630199567,
      "loss": 1.5586,
      "step": 1800
    },
    {
      "epoch": 0.2334267040149393,
      "grad_norm": 0.9165205955505371,
      "learning_rate": 0.00045494710266891084,
      "loss": 1.5403,
      "step": 2000
    },
    {
      "epoch": 0.2567693744164332,
      "grad_norm": 0.8720977306365967,
      "learning_rate": 0.0004489360423178649,
      "loss": 1.5444,
      "step": 2200
    },
    {
      "epoch": 0.2801120448179272,
      "grad_norm": 0.8513222336769104,
      "learning_rate": 0.000442924981966819,
      "loss": 1.5311,
      "step": 2400
    },
    {
      "epoch": 0.3034547152194211,
      "grad_norm": 0.7448260188102722,
      "learning_rate": 0.00043691392161577305,
      "loss": 1.4938,
      "step": 2600
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.6955282092094421,
      "learning_rate": 0.0004309028612647271,
      "loss": 1.5295,
      "step": 2800
    },
    {
      "epoch": 0.35014005602240894,
      "grad_norm": 0.7074407339096069,
      "learning_rate": 0.0004248918009136812,
      "loss": 1.4966,
      "step": 3000
    },
    {
      "epoch": 0.3734827264239029,
      "grad_norm": 0.9372289776802063,
      "learning_rate": 0.00041888074056263525,
      "loss": 1.5013,
      "step": 3200
    },
    {
      "epoch": 0.3968253968253968,
      "grad_norm": 0.647857666015625,
      "learning_rate": 0.0004128696802115893,
      "loss": 1.4939,
      "step": 3400
    },
    {
      "epoch": 0.42016806722689076,
      "grad_norm": 0.7450749278068542,
      "learning_rate": 0.0004068586198605434,
      "loss": 1.4959,
      "step": 3600
    },
    {
      "epoch": 0.44351073762838467,
      "grad_norm": 0.7816101312637329,
      "learning_rate": 0.00040084755950949746,
      "loss": 1.4824,
      "step": 3800
    },
    {
      "epoch": 0.4668534080298786,
      "grad_norm": 0.8706156015396118,
      "learning_rate": 0.0003948364991584515,
      "loss": 1.4978,
      "step": 4000
    },
    {
      "epoch": 0.49019607843137253,
      "grad_norm": 0.5861271023750305,
      "learning_rate": 0.0003888254388074056,
      "loss": 1.484,
      "step": 4200
    },
    {
      "epoch": 0.5135387488328664,
      "grad_norm": 0.6216872930526733,
      "learning_rate": 0.0003828143784563597,
      "loss": 1.4777,
      "step": 4400
    },
    {
      "epoch": 0.5368814192343604,
      "grad_norm": 0.7683542370796204,
      "learning_rate": 0.0003768033181053138,
      "loss": 1.4734,
      "step": 4600
    },
    {
      "epoch": 0.5602240896358543,
      "grad_norm": 0.7216247916221619,
      "learning_rate": 0.00037079225775426785,
      "loss": 1.4732,
      "step": 4800
    },
    {
      "epoch": 0.5835667600373483,
      "grad_norm": 0.9333914518356323,
      "learning_rate": 0.0003647811974032219,
      "loss": 1.4686,
      "step": 5000
    },
    {
      "epoch": 0.6069094304388422,
      "grad_norm": 0.6958417296409607,
      "learning_rate": 0.00035877013705217604,
      "loss": 1.4502,
      "step": 5200
    },
    {
      "epoch": 0.6302521008403361,
      "grad_norm": 0.6581032872200012,
      "learning_rate": 0.0003527590767011301,
      "loss": 1.4475,
      "step": 5400
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.6337523460388184,
      "learning_rate": 0.0003467480163500842,
      "loss": 1.4575,
      "step": 5600
    },
    {
      "epoch": 0.676937441643324,
      "grad_norm": 0.7830178141593933,
      "learning_rate": 0.00034073695599903825,
      "loss": 1.4513,
      "step": 5800
    },
    {
      "epoch": 0.7002801120448179,
      "grad_norm": 0.8764787316322327,
      "learning_rate": 0.0003347258956479923,
      "loss": 1.4445,
      "step": 6000
    },
    {
      "epoch": 0.7236227824463118,
      "grad_norm": 0.7800812721252441,
      "learning_rate": 0.0003287148352969464,
      "loss": 1.4397,
      "step": 6200
    },
    {
      "epoch": 0.7469654528478058,
      "grad_norm": 0.7462452054023743,
      "learning_rate": 0.00032270377494590045,
      "loss": 1.4536,
      "step": 6400
    },
    {
      "epoch": 0.7703081232492998,
      "grad_norm": 0.8572536706924438,
      "learning_rate": 0.00031669271459485457,
      "loss": 1.4294,
      "step": 6600
    },
    {
      "epoch": 0.7936507936507936,
      "grad_norm": 0.7442865371704102,
      "learning_rate": 0.00031068165424380864,
      "loss": 1.4199,
      "step": 6800
    },
    {
      "epoch": 0.8169934640522876,
      "grad_norm": 0.652764081954956,
      "learning_rate": 0.0003046705938927627,
      "loss": 1.4516,
      "step": 7000
    },
    {
      "epoch": 0.8403361344537815,
      "grad_norm": 0.8390893340110779,
      "learning_rate": 0.0002986595335417168,
      "loss": 1.4375,
      "step": 7200
    },
    {
      "epoch": 0.8636788048552755,
      "grad_norm": 0.8314042687416077,
      "learning_rate": 0.00029264847319067084,
      "loss": 1.4329,
      "step": 7400
    },
    {
      "epoch": 0.8870214752567693,
      "grad_norm": 0.6945003271102905,
      "learning_rate": 0.0002866374128396249,
      "loss": 1.4572,
      "step": 7600
    },
    {
      "epoch": 0.9103641456582633,
      "grad_norm": 0.7823024392127991,
      "learning_rate": 0.000280626352488579,
      "loss": 1.4212,
      "step": 7800
    },
    {
      "epoch": 0.9337068160597572,
      "grad_norm": 0.691249668598175,
      "learning_rate": 0.00027461529213753305,
      "loss": 1.4348,
      "step": 8000
    },
    {
      "epoch": 0.9570494864612512,
      "grad_norm": 0.7723042964935303,
      "learning_rate": 0.0002686042317864871,
      "loss": 1.4186,
      "step": 8200
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 0.8396820425987244,
      "learning_rate": 0.0002625931714354412,
      "loss": 1.447,
      "step": 8400
    }
  ],
  "logging_steps": 200,
  "max_steps": 17136,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1040841573995520.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
