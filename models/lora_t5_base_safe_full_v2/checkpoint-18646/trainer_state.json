{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 18646,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.021452322213879653,
      "grad_norm": 0.8901470899581909,
      "learning_rate": 0.000199,
      "loss": 2.9441,
      "step": 200
    },
    {
      "epoch": 0.042904644427759306,
      "grad_norm": 0.8428637385368347,
      "learning_rate": 0.00039900000000000005,
      "loss": 2.5763,
      "step": 400
    },
    {
      "epoch": 0.06435696664163895,
      "grad_norm": 1.0893316268920898,
      "learning_rate": 0.0004972721260883942,
      "loss": 2.4886,
      "step": 600
    },
    {
      "epoch": 0.08580928885551861,
      "grad_norm": 0.6988208889961243,
      "learning_rate": 0.0004917612697013116,
      "loss": 2.4416,
      "step": 800
    },
    {
      "epoch": 0.10726161106939826,
      "grad_norm": 0.8652528524398804,
      "learning_rate": 0.000486250413314229,
      "loss": 2.4333,
      "step": 1000
    },
    {
      "epoch": 0.1287139332832779,
      "grad_norm": 0.6963342428207397,
      "learning_rate": 0.0004807395569271465,
      "loss": 2.4067,
      "step": 1200
    },
    {
      "epoch": 0.15016625549715756,
      "grad_norm": 0.6641124486923218,
      "learning_rate": 0.00047522870054006396,
      "loss": 2.3876,
      "step": 1400
    },
    {
      "epoch": 0.17161857771103722,
      "grad_norm": 0.8021381497383118,
      "learning_rate": 0.00046971784415298143,
      "loss": 2.3588,
      "step": 1600
    },
    {
      "epoch": 0.19307089992491688,
      "grad_norm": 0.6500140428543091,
      "learning_rate": 0.0004642069877658988,
      "loss": 2.3671,
      "step": 1800
    },
    {
      "epoch": 0.21452322213879652,
      "grad_norm": 0.7264184951782227,
      "learning_rate": 0.0004586961313788163,
      "loss": 2.3499,
      "step": 2000
    },
    {
      "epoch": 0.23597554435267618,
      "grad_norm": 1.0314626693725586,
      "learning_rate": 0.00045318527499173375,
      "loss": 2.3635,
      "step": 2200
    },
    {
      "epoch": 0.2574278665665558,
      "grad_norm": 0.8072696924209595,
      "learning_rate": 0.00044767441860465117,
      "loss": 2.3231,
      "step": 2400
    },
    {
      "epoch": 0.27888018878043547,
      "grad_norm": 0.7243157625198364,
      "learning_rate": 0.0004421635622175686,
      "loss": 2.3599,
      "step": 2600
    },
    {
      "epoch": 0.3003325109943151,
      "grad_norm": 0.7214853167533875,
      "learning_rate": 0.00043665270583048607,
      "loss": 2.3251,
      "step": 2800
    },
    {
      "epoch": 0.3217848332081948,
      "grad_norm": 0.7221713066101074,
      "learning_rate": 0.0004311418494434035,
      "loss": 2.3039,
      "step": 3000
    },
    {
      "epoch": 0.34323715542207445,
      "grad_norm": 0.9048866033554077,
      "learning_rate": 0.00042563099305632096,
      "loss": 2.3135,
      "step": 3200
    },
    {
      "epoch": 0.3646894776359541,
      "grad_norm": 0.8932647109031677,
      "learning_rate": 0.00042012013666923844,
      "loss": 2.2848,
      "step": 3400
    },
    {
      "epoch": 0.38614179984983377,
      "grad_norm": 0.6633703112602234,
      "learning_rate": 0.00041460928028215586,
      "loss": 2.2715,
      "step": 3600
    },
    {
      "epoch": 0.40759412206371337,
      "grad_norm": 0.860214352607727,
      "learning_rate": 0.0004090984238950733,
      "loss": 2.3187,
      "step": 3800
    },
    {
      "epoch": 0.42904644427759303,
      "grad_norm": 0.7668505311012268,
      "learning_rate": 0.00040358756750799075,
      "loss": 2.2958,
      "step": 4000
    },
    {
      "epoch": 0.4504987664914727,
      "grad_norm": 0.6758708953857422,
      "learning_rate": 0.00039807671112090823,
      "loss": 2.2858,
      "step": 4200
    },
    {
      "epoch": 0.47195108870535235,
      "grad_norm": 0.7859587669372559,
      "learning_rate": 0.00039256585473382565,
      "loss": 2.2586,
      "step": 4400
    },
    {
      "epoch": 0.493403410919232,
      "grad_norm": 0.7452266216278076,
      "learning_rate": 0.00038705499834674307,
      "loss": 2.2793,
      "step": 4600
    },
    {
      "epoch": 0.5148557331331116,
      "grad_norm": 0.7927861213684082,
      "learning_rate": 0.00038154414195966054,
      "loss": 2.2752,
      "step": 4800
    },
    {
      "epoch": 0.5363080553469913,
      "grad_norm": 0.7103908061981201,
      "learning_rate": 0.00037603328557257796,
      "loss": 2.2843,
      "step": 5000
    },
    {
      "epoch": 0.5577603775608709,
      "grad_norm": 1.0075101852416992,
      "learning_rate": 0.00037052242918549544,
      "loss": 2.2893,
      "step": 5200
    },
    {
      "epoch": 0.5792126997747507,
      "grad_norm": 0.8054925799369812,
      "learning_rate": 0.0003650115727984129,
      "loss": 2.2802,
      "step": 5400
    },
    {
      "epoch": 0.6006650219886303,
      "grad_norm": 0.6998392939567566,
      "learning_rate": 0.00035950071641133033,
      "loss": 2.2734,
      "step": 5600
    },
    {
      "epoch": 0.62211734420251,
      "grad_norm": 0.7326550483703613,
      "learning_rate": 0.00035398986002424776,
      "loss": 2.2686,
      "step": 5800
    },
    {
      "epoch": 0.6435696664163896,
      "grad_norm": 0.7844991683959961,
      "learning_rate": 0.00034847900363716523,
      "loss": 2.277,
      "step": 6000
    },
    {
      "epoch": 0.6650219886302692,
      "grad_norm": 0.9321436285972595,
      "learning_rate": 0.0003429681472500827,
      "loss": 2.2574,
      "step": 6200
    },
    {
      "epoch": 0.6864743108441489,
      "grad_norm": 0.7769318222999573,
      "learning_rate": 0.0003374572908630001,
      "loss": 2.2273,
      "step": 6400
    },
    {
      "epoch": 0.7079266330580285,
      "grad_norm": 0.8669225573539734,
      "learning_rate": 0.00033194643447591755,
      "loss": 2.2915,
      "step": 6600
    },
    {
      "epoch": 0.7293789552719082,
      "grad_norm": 0.7381297945976257,
      "learning_rate": 0.000326435578088835,
      "loss": 2.2618,
      "step": 6800
    },
    {
      "epoch": 0.7508312774857878,
      "grad_norm": 0.6542208790779114,
      "learning_rate": 0.00032092472170175244,
      "loss": 2.2479,
      "step": 7000
    },
    {
      "epoch": 0.7722835996996675,
      "grad_norm": 0.7500130534172058,
      "learning_rate": 0.0003154138653146699,
      "loss": 2.2603,
      "step": 7200
    },
    {
      "epoch": 0.7937359219135471,
      "grad_norm": 0.7722459435462952,
      "learning_rate": 0.00030990300892758734,
      "loss": 2.2576,
      "step": 7400
    },
    {
      "epoch": 0.8151882441274267,
      "grad_norm": 0.828863263130188,
      "learning_rate": 0.00030439215254050476,
      "loss": 2.2148,
      "step": 7600
    },
    {
      "epoch": 0.8366405663413065,
      "grad_norm": 0.7777971029281616,
      "learning_rate": 0.00029888129615342223,
      "loss": 2.212,
      "step": 7800
    },
    {
      "epoch": 0.8580928885551861,
      "grad_norm": 1.0528151988983154,
      "learning_rate": 0.0002933704397663397,
      "loss": 2.2333,
      "step": 8000
    },
    {
      "epoch": 0.8795452107690658,
      "grad_norm": 0.9154015779495239,
      "learning_rate": 0.0002878595833792572,
      "loss": 2.2002,
      "step": 8200
    },
    {
      "epoch": 0.9009975329829454,
      "grad_norm": 0.8558143973350525,
      "learning_rate": 0.00028234872699217455,
      "loss": 2.243,
      "step": 8400
    },
    {
      "epoch": 0.9224498551968251,
      "grad_norm": 0.8967775106430054,
      "learning_rate": 0.000276837870605092,
      "loss": 2.2388,
      "step": 8600
    },
    {
      "epoch": 0.9439021774107047,
      "grad_norm": 0.7876799702644348,
      "learning_rate": 0.0002713270142180095,
      "loss": 2.2254,
      "step": 8800
    },
    {
      "epoch": 0.9653544996245844,
      "grad_norm": 0.9190453290939331,
      "learning_rate": 0.0002658161578309269,
      "loss": 2.2137,
      "step": 9000
    },
    {
      "epoch": 0.986806821838464,
      "grad_norm": 0.8071607351303101,
      "learning_rate": 0.0002603053014438444,
      "loss": 2.2391,
      "step": 9200
    },
    {
      "epoch": 1.0082591440523436,
      "grad_norm": 0.752729594707489,
      "learning_rate": 0.0002547944450567618,
      "loss": 2.2026,
      "step": 9400
    },
    {
      "epoch": 1.0297114662662232,
      "grad_norm": 0.75395268201828,
      "learning_rate": 0.00024928358866967924,
      "loss": 2.2267,
      "step": 9600
    },
    {
      "epoch": 1.051163788480103,
      "grad_norm": 0.7697502374649048,
      "learning_rate": 0.0002437727322825967,
      "loss": 2.2335,
      "step": 9800
    },
    {
      "epoch": 1.0726161106939827,
      "grad_norm": 0.7626249194145203,
      "learning_rate": 0.0002382618758955142,
      "loss": 2.2009,
      "step": 10000
    },
    {
      "epoch": 1.0940684329078623,
      "grad_norm": 0.7496861219406128,
      "learning_rate": 0.0002327510195084316,
      "loss": 2.2278,
      "step": 10200
    },
    {
      "epoch": 1.1155207551217419,
      "grad_norm": 0.8164201378822327,
      "learning_rate": 0.00022724016312134908,
      "loss": 2.167,
      "step": 10400
    },
    {
      "epoch": 1.1369730773356217,
      "grad_norm": 0.7561044096946716,
      "learning_rate": 0.0002217293067342665,
      "loss": 2.1925,
      "step": 10600
    },
    {
      "epoch": 1.1584253995495013,
      "grad_norm": 0.9151776432991028,
      "learning_rate": 0.00021621845034718395,
      "loss": 2.1945,
      "step": 10800
    },
    {
      "epoch": 1.179877721763381,
      "grad_norm": 0.9469212889671326,
      "learning_rate": 0.00021070759396010143,
      "loss": 2.2217,
      "step": 11000
    },
    {
      "epoch": 1.2013300439772605,
      "grad_norm": 0.8973597288131714,
      "learning_rate": 0.00020519673757301885,
      "loss": 2.2266,
      "step": 11200
    },
    {
      "epoch": 1.2227823661911401,
      "grad_norm": 0.8408796191215515,
      "learning_rate": 0.0001996858811859363,
      "loss": 2.2263,
      "step": 11400
    },
    {
      "epoch": 1.24423468840502,
      "grad_norm": 0.7275276184082031,
      "learning_rate": 0.00019417502479885374,
      "loss": 2.2052,
      "step": 11600
    },
    {
      "epoch": 1.2656870106188995,
      "grad_norm": 0.8408278226852417,
      "learning_rate": 0.0001886641684117712,
      "loss": 2.2191,
      "step": 11800
    },
    {
      "epoch": 1.2871393328327791,
      "grad_norm": 0.7572919726371765,
      "learning_rate": 0.00018315331202468864,
      "loss": 2.2162,
      "step": 12000
    },
    {
      "epoch": 1.3085916550466588,
      "grad_norm": 0.7564592361450195,
      "learning_rate": 0.00017764245563760609,
      "loss": 2.1565,
      "step": 12200
    },
    {
      "epoch": 1.3300439772605386,
      "grad_norm": 0.6690434813499451,
      "learning_rate": 0.00017213159925052353,
      "loss": 2.1872,
      "step": 12400
    },
    {
      "epoch": 1.3514962994744182,
      "grad_norm": 0.8894243836402893,
      "learning_rate": 0.00016662074286344098,
      "loss": 2.2066,
      "step": 12600
    },
    {
      "epoch": 1.3729486216882978,
      "grad_norm": 0.8146958351135254,
      "learning_rate": 0.00016110988647635843,
      "loss": 2.1951,
      "step": 12800
    },
    {
      "epoch": 1.3944009439021774,
      "grad_norm": 0.9358688592910767,
      "learning_rate": 0.00015559903008927588,
      "loss": 2.196,
      "step": 13000
    },
    {
      "epoch": 1.415853266116057,
      "grad_norm": 0.8779906034469604,
      "learning_rate": 0.00015008817370219333,
      "loss": 2.1677,
      "step": 13200
    },
    {
      "epoch": 1.4373055883299366,
      "grad_norm": 0.7659319639205933,
      "learning_rate": 0.00014457731731511077,
      "loss": 2.1956,
      "step": 13400
    },
    {
      "epoch": 1.4587579105438164,
      "grad_norm": 0.9995527863502502,
      "learning_rate": 0.00013906646092802822,
      "loss": 2.1592,
      "step": 13600
    },
    {
      "epoch": 1.480210232757696,
      "grad_norm": 0.9621068239212036,
      "learning_rate": 0.00013355560454094567,
      "loss": 2.2056,
      "step": 13800
    },
    {
      "epoch": 1.5016625549715756,
      "grad_norm": 0.8390532732009888,
      "learning_rate": 0.00012804474815386312,
      "loss": 2.1936,
      "step": 14000
    },
    {
      "epoch": 1.5231148771854555,
      "grad_norm": 0.8371026515960693,
      "learning_rate": 0.00012253389176678056,
      "loss": 2.219,
      "step": 14200
    },
    {
      "epoch": 1.544567199399335,
      "grad_norm": 0.916287362575531,
      "learning_rate": 0.00011702303537969801,
      "loss": 2.2012,
      "step": 14400
    },
    {
      "epoch": 1.5660195216132147,
      "grad_norm": 0.6595617532730103,
      "learning_rate": 0.00011151217899261546,
      "loss": 2.2031,
      "step": 14600
    },
    {
      "epoch": 1.5874718438270943,
      "grad_norm": 0.7805124521255493,
      "learning_rate": 0.0001060013226055329,
      "loss": 2.1711,
      "step": 14800
    },
    {
      "epoch": 1.6089241660409739,
      "grad_norm": 0.787929892539978,
      "learning_rate": 0.00010049046621845034,
      "loss": 2.1575,
      "step": 15000
    },
    {
      "epoch": 1.6303764882548535,
      "grad_norm": 0.9496835470199585,
      "learning_rate": 9.49796098313678e-05,
      "loss": 2.1754,
      "step": 15200
    },
    {
      "epoch": 1.651828810468733,
      "grad_norm": 0.8150882124900818,
      "learning_rate": 8.946875344428525e-05,
      "loss": 2.1774,
      "step": 15400
    },
    {
      "epoch": 1.673281132682613,
      "grad_norm": 0.6386053562164307,
      "learning_rate": 8.395789705720269e-05,
      "loss": 2.1833,
      "step": 15600
    },
    {
      "epoch": 1.6947334548964925,
      "grad_norm": 0.9834226369857788,
      "learning_rate": 7.844704067012013e-05,
      "loss": 2.1837,
      "step": 15800
    },
    {
      "epoch": 1.7161857771103723,
      "grad_norm": 0.7673431634902954,
      "learning_rate": 7.293618428303758e-05,
      "loss": 2.166,
      "step": 16000
    },
    {
      "epoch": 1.737638099324252,
      "grad_norm": 0.6534538865089417,
      "learning_rate": 6.742532789595503e-05,
      "loss": 2.1929,
      "step": 16200
    },
    {
      "epoch": 1.7590904215381316,
      "grad_norm": 0.7778505086898804,
      "learning_rate": 6.191447150887248e-05,
      "loss": 2.1579,
      "step": 16400
    },
    {
      "epoch": 1.7805427437520112,
      "grad_norm": 0.8709551692008972,
      "learning_rate": 5.640361512178993e-05,
      "loss": 2.1658,
      "step": 16600
    },
    {
      "epoch": 1.8019950659658908,
      "grad_norm": 0.8030143976211548,
      "learning_rate": 5.089275873470737e-05,
      "loss": 2.1831,
      "step": 16800
    },
    {
      "epoch": 1.8234473881797704,
      "grad_norm": 0.6618793606758118,
      "learning_rate": 4.538190234762482e-05,
      "loss": 2.1895,
      "step": 17000
    },
    {
      "epoch": 1.84489971039365,
      "grad_norm": 0.8298338651657104,
      "learning_rate": 3.9871045960542275e-05,
      "loss": 2.165,
      "step": 17200
    },
    {
      "epoch": 1.8663520326075298,
      "grad_norm": 0.7459065318107605,
      "learning_rate": 3.4360189573459716e-05,
      "loss": 2.1645,
      "step": 17400
    },
    {
      "epoch": 1.8878043548214094,
      "grad_norm": 0.8545072078704834,
      "learning_rate": 2.884933318637716e-05,
      "loss": 2.1849,
      "step": 17600
    },
    {
      "epoch": 1.9092566770352892,
      "grad_norm": 0.8973776698112488,
      "learning_rate": 2.3338476799294612e-05,
      "loss": 2.1437,
      "step": 17800
    },
    {
      "epoch": 1.9307089992491688,
      "grad_norm": 0.8934454321861267,
      "learning_rate": 1.782762041221206e-05,
      "loss": 2.1865,
      "step": 18000
    },
    {
      "epoch": 1.9521613214630484,
      "grad_norm": 0.7627860307693481,
      "learning_rate": 1.2316764025129506e-05,
      "loss": 2.159,
      "step": 18200
    },
    {
      "epoch": 1.973613643676928,
      "grad_norm": 0.8339837789535522,
      "learning_rate": 6.805907638046953e-06,
      "loss": 2.1853,
      "step": 18400
    },
    {
      "epoch": 1.9950659658908076,
      "grad_norm": 0.7489309906959534,
      "learning_rate": 1.2950512509643998e-06,
      "loss": 2.1736,
      "step": 18600
    }
  ],
  "logging_steps": 200,
  "max_steps": 18646,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2147409542615040.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
