{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 9323,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.021452322213879653,
      "grad_norm": 0.8901470899581909,
      "learning_rate": 0.000199,
      "loss": 2.9441,
      "step": 200
    },
    {
      "epoch": 0.042904644427759306,
      "grad_norm": 0.8428637385368347,
      "learning_rate": 0.00039900000000000005,
      "loss": 2.5763,
      "step": 400
    },
    {
      "epoch": 0.06435696664163895,
      "grad_norm": 1.0893316268920898,
      "learning_rate": 0.0004972721260883942,
      "loss": 2.4886,
      "step": 600
    },
    {
      "epoch": 0.08580928885551861,
      "grad_norm": 0.6988208889961243,
      "learning_rate": 0.0004917612697013116,
      "loss": 2.4416,
      "step": 800
    },
    {
      "epoch": 0.10726161106939826,
      "grad_norm": 0.8652528524398804,
      "learning_rate": 0.000486250413314229,
      "loss": 2.4333,
      "step": 1000
    },
    {
      "epoch": 0.1287139332832779,
      "grad_norm": 0.6963342428207397,
      "learning_rate": 0.0004807395569271465,
      "loss": 2.4067,
      "step": 1200
    },
    {
      "epoch": 0.15016625549715756,
      "grad_norm": 0.6641124486923218,
      "learning_rate": 0.00047522870054006396,
      "loss": 2.3876,
      "step": 1400
    },
    {
      "epoch": 0.17161857771103722,
      "grad_norm": 0.8021381497383118,
      "learning_rate": 0.00046971784415298143,
      "loss": 2.3588,
      "step": 1600
    },
    {
      "epoch": 0.19307089992491688,
      "grad_norm": 0.6500140428543091,
      "learning_rate": 0.0004642069877658988,
      "loss": 2.3671,
      "step": 1800
    },
    {
      "epoch": 0.21452322213879652,
      "grad_norm": 0.7264184951782227,
      "learning_rate": 0.0004586961313788163,
      "loss": 2.3499,
      "step": 2000
    },
    {
      "epoch": 0.23597554435267618,
      "grad_norm": 1.0314626693725586,
      "learning_rate": 0.00045318527499173375,
      "loss": 2.3635,
      "step": 2200
    },
    {
      "epoch": 0.2574278665665558,
      "grad_norm": 0.8072696924209595,
      "learning_rate": 0.00044767441860465117,
      "loss": 2.3231,
      "step": 2400
    },
    {
      "epoch": 0.27888018878043547,
      "grad_norm": 0.7243157625198364,
      "learning_rate": 0.0004421635622175686,
      "loss": 2.3599,
      "step": 2600
    },
    {
      "epoch": 0.3003325109943151,
      "grad_norm": 0.7214853167533875,
      "learning_rate": 0.00043665270583048607,
      "loss": 2.3251,
      "step": 2800
    },
    {
      "epoch": 0.3217848332081948,
      "grad_norm": 0.7221713066101074,
      "learning_rate": 0.0004311418494434035,
      "loss": 2.3039,
      "step": 3000
    },
    {
      "epoch": 0.34323715542207445,
      "grad_norm": 0.9048866033554077,
      "learning_rate": 0.00042563099305632096,
      "loss": 2.3135,
      "step": 3200
    },
    {
      "epoch": 0.3646894776359541,
      "grad_norm": 0.8932647109031677,
      "learning_rate": 0.00042012013666923844,
      "loss": 2.2848,
      "step": 3400
    },
    {
      "epoch": 0.38614179984983377,
      "grad_norm": 0.6633703112602234,
      "learning_rate": 0.00041460928028215586,
      "loss": 2.2715,
      "step": 3600
    },
    {
      "epoch": 0.40759412206371337,
      "grad_norm": 0.860214352607727,
      "learning_rate": 0.0004090984238950733,
      "loss": 2.3187,
      "step": 3800
    },
    {
      "epoch": 0.42904644427759303,
      "grad_norm": 0.7668505311012268,
      "learning_rate": 0.00040358756750799075,
      "loss": 2.2958,
      "step": 4000
    },
    {
      "epoch": 0.4504987664914727,
      "grad_norm": 0.6758708953857422,
      "learning_rate": 0.00039807671112090823,
      "loss": 2.2858,
      "step": 4200
    },
    {
      "epoch": 0.47195108870535235,
      "grad_norm": 0.7859587669372559,
      "learning_rate": 0.00039256585473382565,
      "loss": 2.2586,
      "step": 4400
    },
    {
      "epoch": 0.493403410919232,
      "grad_norm": 0.7452266216278076,
      "learning_rate": 0.00038705499834674307,
      "loss": 2.2793,
      "step": 4600
    },
    {
      "epoch": 0.5148557331331116,
      "grad_norm": 0.7927861213684082,
      "learning_rate": 0.00038154414195966054,
      "loss": 2.2752,
      "step": 4800
    },
    {
      "epoch": 0.5363080553469913,
      "grad_norm": 0.7103908061981201,
      "learning_rate": 0.00037603328557257796,
      "loss": 2.2843,
      "step": 5000
    },
    {
      "epoch": 0.5577603775608709,
      "grad_norm": 1.0075101852416992,
      "learning_rate": 0.00037052242918549544,
      "loss": 2.2893,
      "step": 5200
    },
    {
      "epoch": 0.5792126997747507,
      "grad_norm": 0.8054925799369812,
      "learning_rate": 0.0003650115727984129,
      "loss": 2.2802,
      "step": 5400
    },
    {
      "epoch": 0.6006650219886303,
      "grad_norm": 0.6998392939567566,
      "learning_rate": 0.00035950071641133033,
      "loss": 2.2734,
      "step": 5600
    },
    {
      "epoch": 0.62211734420251,
      "grad_norm": 0.7326550483703613,
      "learning_rate": 0.00035398986002424776,
      "loss": 2.2686,
      "step": 5800
    },
    {
      "epoch": 0.6435696664163896,
      "grad_norm": 0.7844991683959961,
      "learning_rate": 0.00034847900363716523,
      "loss": 2.277,
      "step": 6000
    },
    {
      "epoch": 0.6650219886302692,
      "grad_norm": 0.9321436285972595,
      "learning_rate": 0.0003429681472500827,
      "loss": 2.2574,
      "step": 6200
    },
    {
      "epoch": 0.6864743108441489,
      "grad_norm": 0.7769318222999573,
      "learning_rate": 0.0003374572908630001,
      "loss": 2.2273,
      "step": 6400
    },
    {
      "epoch": 0.7079266330580285,
      "grad_norm": 0.8669225573539734,
      "learning_rate": 0.00033194643447591755,
      "loss": 2.2915,
      "step": 6600
    },
    {
      "epoch": 0.7293789552719082,
      "grad_norm": 0.7381297945976257,
      "learning_rate": 0.000326435578088835,
      "loss": 2.2618,
      "step": 6800
    },
    {
      "epoch": 0.7508312774857878,
      "grad_norm": 0.6542208790779114,
      "learning_rate": 0.00032092472170175244,
      "loss": 2.2479,
      "step": 7000
    },
    {
      "epoch": 0.7722835996996675,
      "grad_norm": 0.7500130534172058,
      "learning_rate": 0.0003154138653146699,
      "loss": 2.2603,
      "step": 7200
    },
    {
      "epoch": 0.7937359219135471,
      "grad_norm": 0.7722459435462952,
      "learning_rate": 0.00030990300892758734,
      "loss": 2.2576,
      "step": 7400
    },
    {
      "epoch": 0.8151882441274267,
      "grad_norm": 0.828863263130188,
      "learning_rate": 0.00030439215254050476,
      "loss": 2.2148,
      "step": 7600
    },
    {
      "epoch": 0.8366405663413065,
      "grad_norm": 0.7777971029281616,
      "learning_rate": 0.00029888129615342223,
      "loss": 2.212,
      "step": 7800
    },
    {
      "epoch": 0.8580928885551861,
      "grad_norm": 1.0528151988983154,
      "learning_rate": 0.0002933704397663397,
      "loss": 2.2333,
      "step": 8000
    },
    {
      "epoch": 0.8795452107690658,
      "grad_norm": 0.9154015779495239,
      "learning_rate": 0.0002878595833792572,
      "loss": 2.2002,
      "step": 8200
    },
    {
      "epoch": 0.9009975329829454,
      "grad_norm": 0.8558143973350525,
      "learning_rate": 0.00028234872699217455,
      "loss": 2.243,
      "step": 8400
    },
    {
      "epoch": 0.9224498551968251,
      "grad_norm": 0.8967775106430054,
      "learning_rate": 0.000276837870605092,
      "loss": 2.2388,
      "step": 8600
    },
    {
      "epoch": 0.9439021774107047,
      "grad_norm": 0.7876799702644348,
      "learning_rate": 0.0002713270142180095,
      "loss": 2.2254,
      "step": 8800
    },
    {
      "epoch": 0.9653544996245844,
      "grad_norm": 0.9190453290939331,
      "learning_rate": 0.0002658161578309269,
      "loss": 2.2137,
      "step": 9000
    },
    {
      "epoch": 0.986806821838464,
      "grad_norm": 0.8071607351303101,
      "learning_rate": 0.0002603053014438444,
      "loss": 2.2391,
      "step": 9200
    }
  ],
  "logging_steps": 200,
  "max_steps": 18646,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1074094161592320.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
