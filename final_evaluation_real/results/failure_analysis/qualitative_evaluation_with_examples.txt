======================================================================
QUALITATIVE EVALUATION FOR FINAL REPORT
======================================================================

This document provides example outputs and qualitative analysis for the paper.


======================================================================
1. BASELINE MODEL COMPARISON
======================================================================

To demonstrate the necessity of fine-tuning, we compare baseline models:

--- Example 1.1: Baseline Vanilla (No Fine-tuning) ---

Prompt: Generate a diabetes-friendly Neiman-Marcus Cake recipe.

Generated Recipe:
Preheat the oven to 350°F (180°C) and grease a 9x9x2-inch baking pan. Grease and flour a 9x9x2-inch baking pan. Set aside. In a large mixing bowl, mix together the flour, baking powder, baking soda, and salt. Add the wet ingredients to the dry ingredients and mix well. Add the wet ingredients to the dry ingredients and mix well. Add the wet ingredients to the dry ingredients and mix well. [...]

Analysis: This example shows the base FLAN-T5 model's limitations.
Key issues: (1) No structured Ingredients/Instructions sections,
(2) Uses forbidden ingredients without diabetes-friendly substitutes,
(3) Generic recipe that ignores diabetes constraints.

--- Example 1.2: Baseline with Keywords in Prompt ---

Prompt: Generate a diabetes-friendly Boiled Crawfish recipe.
Use diabetes-friendly ingredients like: whole wheat, brown rice, olive oil...
Avoid: white flour, sugar, butter, cream...

Generated Recipe:
Use diabetes-friendly ingredients like: whole wheat flour, brown rice, olive oil, vegetables, lean protein, low-fat dairy, beans, nuts, fish Avoid: white flour, white rice, sugar, butter, cream, fried foods

Analysis: Even with explicit keywords in the prompt, the model fails.
While prompting helps (Vanilla: 72% failure → Keywords: 43% failure),
it still produces recipes with forbidden ingredients or missing structure.
This demonstrates that prompting alone is insufficient for this task.


======================================================================
2. EFFECT OF TRAINING DATA SIZE
======================================================================

--- Example 2.1: Safe LoRA 1K (Insufficient Data) ---

Dish: Easy Cheese Danish

Generated Recipe:
Easy cheese danishes are a great option for diabetics. You can make these danishes as a side dish or as a side dish.

Analysis: With only 1K training examples, the model exhibits structural issues:
- Often generates very short, incomplete recipes
- Missing proper Ingredients or Instructions sections (98.6% missing)
- Demonstrates that 1K examples insufficient for learning recipe structure

--- Example 2.2: Safe LoRA 5K (Improved Structure) ---

Dish: Dill Dip

Generated Recipe:
Ingredients: dill, onion, garlic cloves, salt, pepper Instructions: 1. preheat oven to 350 degrees 2. in a large bowl , combine onion , garlic , salt , pepper , garlic , salt , pepper , and pepper 3. in a large bowl , combine onion , garlic , salt , pepper , pepper , and pepper 4. in a large bowl , combine onion , garlic , salt , pepper , pepper , and pepper 5. [...]

Analysis: At 5K examples, structural quality dramatically improves:
- Proper Ingredients and Instructions sections (100% have ingredients)
- Measurements and cooking instructions included
- LCR improves from 31.2% → 72.8%
- This represents the 'structural competence threshold'

--- Example 2.3: Safe LoRA Full (~231K examples) ---

Dish: Mom's Spaghetti In Vodka Sauce Recipe

Generated Recipe:
Ingredients: olive oil, onion, garlic cloves, celery ribs, celery ribs, celery ribs, celery ribs, celery ribs, salt, pepper Instructions: 1. heat oil in a large skillet over medium heat 2. add onion , garlic , celery ribs , celery ribs , celery ribs , celery ribs , celery ribs , celery ribs , celery ribs , celery ribs , celery ribs , celery ribs , celery ribs , celery ribs , celery ribs , celery r...

Analysis: The full dataset model achieves best performance:
- 84.2% LCR (vs 72.8% for 5K)
- Consistent structure and detailed instructions
- However, diminishing returns: 10K→Full only gains +1.5%
- Still fails on inherently difficult categories (desserts)


======================================================================
3. IMPACT OF DATA FILTERING
======================================================================

Comparing models trained on same data size but different quality:

--- Example 3.1: Unfiltered LoRA 5K (47.9% LCR) ---

Dish: Heavenly Caramels(Microwave)  

Generated Recipe:
Ingredients: caramels, butter, sugar, salt, vanilla extract, vanilla extract Instructions: 1. melt butter in a large saucepan over medium heat 2. add the caramels , sugar , salt , vanilla extract , vanilla extract , and vanilla extract 3. add the caramels , sugar , salt , vanilla extract , and vanilla extract 4. add the caramels , sugar , salt , vanilla extract , and vanilla extract 5. [...]

Analysis: Trained on unfiltered data, this model frequently generates:
- Recipes with forbidden ingredients (sugar, white flour, butter)
- 52.1% failure rate despite having proper structure
- Learned both safe AND unsafe patterns from training data

--- Example 3.2: Safe LoRA 5K (72.8% LCR) ---

Dish: Dill Dip

Generated Recipe:
Ingredients: dill, onion, garlic cloves, salt, pepper Instructions: 1. preheat oven to 350 degrees 2. in a large bowl , combine onion , garlic , salt , pepper , garlic , salt , pepper , and pepper 3. in a large bowl , combine onion , garlic , salt , pepper , pepper , and pepper 4. in a large bowl , combine onion , garlic , salt , pepper , pepper , and pepper 5. [...]

Analysis: Same model size, filtered training data:
- 27.2% failure rate (24.9% improvement over unfiltered)
- Consistently uses diabetes-friendly ingredients
- KEY FINDING: Data quality > data quantity for safety


======================================================================
4. FAILURE PATTERNS BY DISH TYPE
======================================================================

--- Example 4.1: Dessert Recipe (Highest Failure Rate) ---

Dish: 14 Layer Chocolate Cake (Safe LoRA Full)

Generated Recipe:
Ingredients: chocolate cake mix, butter, eggs, milk, vanilla extract, salt, pepper Instructions: 1. preheat oven to 350 degrees f 2. in a large bowl , combine the chocolate cake mix , butter , eggs , milk , vanilla extract , salt , pepper , and salt 3. mix well 4. [...]

Analysis: Desserts show highest failure rates across ALL models:
- Safe Full: 33% of failures are desserts
- Safe 5K: 48.3% of failures are desserts
- Fundamental constraint conflict: desserts require sugar/flour
- Even best models struggle to substitute effectively

--- Example 4.2: Protein-Based Recipe (Low Failure Rate) ---

Dish: French Chicken Stew (Safe LoRA Full)

Generated Recipe:
Ingredients: boneless skinless chicken breasts, onion, garlic cloves, fresh parsley, fresh parsley, fresh parsley, fresh parsley, fresh parsley, fresh parsley, fresh parsley, fresh parmesan cheese Instructions: 1. in a large skillet , saute the onion , garlic , parsley , parsley , parsley , parsley , parsley , parsley , parsley , parmesan cheese , parmesan cheese , parmesan cheese , parmesan chees...

Analysis: Protein-based dishes show much lower failure rates:
- Naturally align with diabetes-friendly constraints
- Easy to incorporate required ingredients (vegetables, olive oil)
- Fewer forbidden ingredients in traditional preparation


======================================================================
5. REINFORCEMENT LEARNING FAILURE (NEGATIVE RESULT)
======================================================================

We attempted RL fine-tuning with REINFORCE and binary LCR rewards.
Unfortunately, both RL models suffered catastrophic collapse:

--- Example 5.1: Safe LoRA Full + RL (Model Collapse) ---

Dish: Simple Hot Chocolate For One 

Generated Recipe:
Make a simple hot chocolate for one person.

Analysis: RL training caused complete model collapse:
- Repetitive loops ('add chicken... add chicken... add chicken...')
- No coherent recipe structure
- Performance degraded from 84.2% → 27.7% LCR
- Root cause: Reward saturation led to vanishing gradients
- When all samples pass (reward=1.0), advantages=0, no learning signal

LESSON: RL requires careful reward shaping to avoid collapse.
Binary rewards insufficient for this constrained generation task.


======================================================================
6. KEY QUALITATIVE TRENDS
======================================================================

TREND 1: Missing Required Keywords > Having Forbidden
  - Across all models, missing required keywords is the dominant failure mode
  - Models learn to avoid forbidden terms more easily than include required ones
  - Even Safe Full: 49.5% of failures are missing required only

TREND 2: Structural Competence Emerges at 5K Examples
  - 1K: 98.6% missing ingredients section, incomplete recipes
  - 5K: 0% missing ingredients, proper structure achieved
  - This represents a clear threshold for recipe generation

TREND 3: Dish Type Predicts Difficulty
  - Desserts: 60-80% failure rate (inherent constraint conflict)
  - Carbs: 40-60% failure rate (hard to substitute grains)
  - Protein: 10-30% failure rate (naturally diabetes-friendly)
  - Pattern consistent across all model sizes

TREND 4: Data Quality Matters More Than Quantity
  - Unfiltered 5K: 52.1% failure despite proper structure
  - Safe 5K: 27.2% failure, same data size
  - +24.9% improvement from filtering alone
  - Safe 5K outperforms Unfiltered despite being smaller model

TREND 5: Diminishing Returns After 10K
  - 1K→5K: +41.6% improvement (huge jump)
  - 5K→10K: +9.9% improvement (significant)
  - 10K→Full: +1.5% improvement (minimal)
  - Suggests 10K examples capture most learnable patterns
